{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351f2c51",
   "metadata": {},
   "source": [
    "Import all the base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034a38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert, butter, filtfilt, find_peaks\n",
    "from scipy.ndimage import generic_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6d134",
   "metadata": {},
   "source": [
    "## Step 1: Use Bartholomew's distance to identify potential task switching points.\n",
    "\n",
    "Calculate whether the Bhattacharyya distance between 500 milliseconds before and after a given time point exceeds the average of the previous 10 seconds plus 3SD, using 40-millisecond intervals.  \n",
    "Save the time point into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import welch\n",
    "\n",
    "#Calculate the bhattacharyya distance\n",
    "def bhattacharyya_distance(psd1, psd2):\n",
    "    \"\"\"\n",
    "    Calculate the Bhattacharyya distance between two discrete distributions (power spectra).\n",
    "    psd1 and psd2 should be two power spectral density arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalization to probability distribution\n",
    "    p = psd1 / (np.sum(psd1) + 1e-10)\n",
    "    q = psd2 / (np.sum(psd2) + 1e-10)\n",
    "    #bc = 1 mean totally same, bc = 0 mean totally different\n",
    "    bc = np.sum(np.sqrt(p * q))\n",
    "    #bhattacharyya distance=-ln(bc)\n",
    "    return -np.log(bc + 1e-10)\n",
    "\n",
    "\n",
    "def detect_task_switch_by_bhattacharyya(eeg_data_frame, gfp, sfreq=256):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        eeg_data_frame (_type_): pandas dataframe (Row: Time point, Column: EEG channel)\n",
    "        gfp (_type_): numpy array of every time point's gfp\n",
    "        sfreq (int, optional): 256hz. Defaults to 256.\n",
    "    return:\n",
    "        A list of time points that may be task switch time point\n",
    "    \"\"\"\n",
    "    entire_time_len = len(eeg_data_frame)\n",
    "    \n",
    "    #use 40ms as the step length of window\n",
    "    step_len = int(0.040 * sfreq)\n",
    "    #use 500 ms as the window length\n",
    "    window_len = int(0.5 * sfreq)\n",
    "    \n",
    "    #Use 10s as the baseline length as filter\n",
    "    #Later use 10s (mean + 3SD) to filt\n",
    "    baseline_len = int(10 * sfreq)\n",
    "    \n",
    "    \n",
    "    #Trans pandas dataframe to numpy array to calculate quicker\n",
    "    #Filp to row is channels, column is time points\n",
    "    eeg_data_numpy = eeg_data_frame.values.T #Now the shape is (channel, time)\n",
    "    \n",
    "    #Set variable to store the candidate time points\n",
    "    candidate_time_points = []\n",
    "    bd_scores = []\n",
    "    \n",
    "    \n",
    "    #Traverse the entire dataset, save the bd_scores with time points\n",
    "    for i in range(window_len, entire_time_len-window_len, step_len):\n",
    "        #Calculate the bhattacharyya distance between front window and back window\n",
    "        \n",
    "        #The data of from window and back window. \n",
    "        #Remember now the numpy array is (channel, time) so we can do that. \n",
    "        front_window = eeg_data_numpy[:, i-window_len:i]\n",
    "        back_window = eeg_data_numpy[:, i:i+window_len]\n",
    "        \n",
    "        # Spectrum Analysis, get front window and back window's psd(power spectral density)\n",
    "        _, psd_front_window = welch(front_window, fs=sfreq, nperseg=window_len)\n",
    "        _, psd_back_window = welch(back_window, fs=sfreq, nperseg=window_len)\n",
    "        \n",
    "        avg_psd_front_window = np.mean(psd_front_window, axis=0)\n",
    "        avg_psd_back_window = np.mean(psd_back_window, axis=0)\n",
    "        \n",
    "        distance = bhattacharyya_distance(avg_psd_front_window, avg_psd_back_window)\n",
    "        \n",
    "        \n",
    "        #Name bhattacharyya_distance bd_scores to make sure it's clear\n",
    "        bd_scores.append((i, distance))\n",
    "    \n",
    "    #Filter the possible task switch time points\n",
    "    for idx,(time_point, bd) in enumerate(bd_scores):\n",
    "        #The fist 10s is the baseline, so we skip it, assume not task switch happen on first 10s\n",
    "        if time_point < baseline_len:\n",
    "            continue\n",
    "        \n",
    "        #Select the scores in front 10s of time point\n",
    "        front_bd_scores = [s for p, s in bd_scores if time_point - baseline_len <= p < time_point]\n",
    "        \n",
    "        #Make sure there is no error happen\n",
    "        #Normally should not happen, but just for safety\n",
    "        if not front_bd_scores:\n",
    "            print(f\"Error: No scores found for time point {time_point}\")\n",
    "            continue\n",
    "        #The threshold is mean + 3SD of 10s before time point\n",
    "        threshold = np.mean(front_bd_scores) + 3 * np.std(front_bd_scores)\n",
    "        \n",
    "        if bd > threshold:\n",
    "            candidate_time_points.append(time_point)\n",
    "    return candidate_time_points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54f00c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average power for a specific frequency(alpha/theta) band using the Welch method.\n",
    "def get_multi_channel_band_power(eeg_data, sfreq, band):\n",
    "\n",
    "    f, psd = welch(eeg_data, fs=sfreq, nperseg=eeg_data.shape[1], axis=-1)\n",
    "    idx = np.logical_and(f >= band[0], f <= band[1])\n",
    "    band_psd = psd[:, idx]\n",
    "    return np.mean(band_psd)\n",
    "\n",
    "\n",
    "#Method 1: No detail(Use 200ms as the base)\n",
    "def alpha_theta_check(candidate_time_points, eeg_data_frame, sfreq=256):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        candidate_time_points (list): A list of possible task switch times point\n",
    "        eeg_data_frame: A pandas dataframe of EEG data\n",
    "        \n",
    "        \n",
    "    Check the alpha and theta power for a candidate time point.\n",
    "    Use 300ms as the window size to check.\n",
    "        Check range is 15000ms near which is 750ms before and after the candidate time point.\n",
    "        Check if the power of alpha significant increase with theta significant decrease(or reverse) happened in 200ms. \n",
    "            (By comparing the power of alpha and theta in 200ms before and after)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Set alpha and theta bands as defauly\n",
    "    alphs_band = (8, 13)\n",
    "    theta_band = (4, 8)\n",
    "    \n",
    "    \n",
    "    #Set list save verified time points\n",
    "    verified_segments = []\n",
    "    \n",
    "    #The window size is 200ms\n",
    "    check_window = int(0.2 * sfreq)\n",
    "    #The range is 750ms before and after the candidate time point\n",
    "    half_range = int(0.75 * sfreq)\n",
    "    #use 40ms as the step length of window\n",
    "    step_len = int(0.040 * sfreq)\n",
    "    \n",
    "    #Trans pandas dataframe to numpy array to calculate quicker\n",
    "    #Filp to row is channels, column is time points\n",
    "    eeg_data_numpy = eeg_data_frame.values.T #Now the shape is (channel, time)\n",
    "    \n",
    "    for time_point in candidate_time_points:\n",
    "        #Set the scope of checking(1500ms)\n",
    "        start_scope = max(0, time_point - half_range)\n",
    "        end_scope = min(len(eeg_data_frame), time_point + half_range)\n",
    "\n",
    "        #The scope must be larger than the window size times 2(otherwise it is meaningless)\n",
    "        if end_scope - start_scope < check_window*2:\n",
    "            break\n",
    "        \n",
    "        #Set the variable\n",
    "        alpha_change = False\n",
    "        theta_change = False\n",
    "        change_start = time_point\n",
    "        change_end = time_point\n",
    "        \n",
    "        #Start checking:\n",
    "        for time in range(start_scope, end_scope - check_window, step_len):\n",
    "            #Set fron half window and post half window(200ms each)\n",
    "            pre_window = eeg_data_numpy[:, time : time + check_window]\n",
    "            post_window = eeg_data_numpy[:, time + check_window:time + 2*check_window]\n",
    "            \n",
    "            #Count the mean power of Alpha/Theta in pre and post window\n",
    "            alpha_pre = get_multi_channel_band_power(pre_window, sfreq, alphs_band)\n",
    "            alphs_post = get_multi_channel_band_power(post_window, sfreq, alphs_band)\n",
    "            theta_pre = get_multi_channel_band_power(pre_window, sfreq, theta_band)\n",
    "            theta_post = get_multi_channel_band_power(post_window, sfreq, theta_band)\n",
    "            \n",
    "            #Count the change ratio of Alpha/Theta\n",
    "            alphs_change_ratio = (alphs_post - alpha_pre) / (alpha_pre + 1e-10)\n",
    "            theta_change_ratio = (theta_post - theta_pre) / (theta_pre + 1e-10)\n",
    "            \n",
    "            \n",
    "            if (abs(alphs_change_ratio) >= 0.3 and abs(theta_change_ratio) >= 0.2):\n",
    "                if ((alphs_change_ratio < 0 and theta_change_ratio > 0) or (alphs_change_ratio > 0 and theta_change_ratio < 0)):\n",
    "                    alpha_change = True\n",
    "                    theta_change = True\n",
    "                    change_start = min(change_start, time)\n",
    "                    change_end = max(change_end, time+check_window)\n",
    "        \n",
    "        if alpha_change and theta_change:\n",
    "            verified_segments.append((change_start, change_end))\n",
    "            \n",
    "\n",
    "\n",
    "#Method 2: With detail, using envelope\n",
    "\n",
    "def butter_bandpass_filter(data, low, high, sfreq=256, order=4):\n",
    "    nyq = 0.5 * sfreq\n",
    "    low_cut = low / nyq\n",
    "    high_cut = high / nyq\n",
    "    b, a = butter(order, [low_cut, high_cut], btype='band')\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def verify_alpha_theta_2(eeg_data_frame, candidate_time_points, sfreq=256):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        candidate_time_points (list): A list of possible task switch times point\n",
    "        eeg_data_frame: A pandas dataframe of EEG data\n",
    "        sfreq (int): Sampling frequency of the EEG data(256hz)\n",
    "    \"\"\"\n",
    "\n",
    "    entire_time_len = len(eeg_data_frame)\n",
    "    \n",
    "    #Get the average signal of all signal(First, take the average of all channels, then calculate the envelope to reflect the overall trend)\n",
    "    average_signal = eeg_data_frame.mean(axis=1).values\n",
    "    \n",
    "    #Get the envelope of alpha and theta band\n",
    "    alpha_envelope = np.abs(hilbert(butter_bandpass_filter(average_signal, 8, 13, sfreq=sfreq)))\n",
    "    theta_envelope = np.abs(hilbert(butter_bandpass_filter(average_signal, 4, 8, sfreq=sfreq)))\n",
    "    \n",
    "    #Since power is V^2 and envelope is V, we need to square the envelope if we want to use the same standard value in paper.\n",
    "    alpha_envelope_sq = alpha_envelope**2\n",
    "    theta_envelope_sq = theta_envelope**2\n",
    "    \n",
    "    #Set list save verified time points\n",
    "    verified_segments = []\n",
    "    #The window size is 200ms\n",
    "    check_window = int(0.2 * sfreq)\n",
    "    #The range is 750ms before and after the candidate time point\n",
    "    half_range = int(0.75 * sfreq)\n",
    "    #use 40ms as the step length of window\n",
    "    step_len = int(0.040 * sfreq)\n",
    "\n",
    "    for time_point in candidate_time_points:\n",
    "        search_start = max(0, time_point - half_range)\n",
    "        search_end = min(entire_time_len, time_point + half_range)\n",
    "        \n",
    "        #Set the variable\n",
    "        coarse_start = None\n",
    "        \n",
    "        for time in range(search_start, search_end - check_window, step_len):\n",
    "            \n",
    "            alpha_pre = np.mean(alpha_envelope_sq[time : time+check_window])\n",
    "            alpha_post = np.mean(alpha_envelope_sq[time+check_window : time+2*check_window])\n",
    "            theta_pre = np.mean(theta_envelope_sq[time : time+check_window])\n",
    "            theta_post = np.mean(theta_envelope_sq[time+check_window : time+2*check_window])\n",
    "            \n",
    "            alpha_ratio = (alpha_post - alpha_pre) / (alpha_pre + 1e-10)\n",
    "            theta_ratio = (theta_post - theta_pre) / (theta_pre + 1e-10)\n",
    "            \n",
    "            if abs(alpha_ratio) >= 0.3 and abs(theta_ratio) >= 0.2:\n",
    "                if ((alpha_ratio < 0 and theta_ratio > 0) or (alpha_ratio > 0 and theta_ratio < 0)):\n",
    "                    coarse_start = time\n",
    "                    break\n",
    "            \n",
    "            #If found the coarse start. We want to find more details of when the task swich start and end\n",
    "            #Try to find the peak of alpha and theta gradient\n",
    "            if coarse_start is not None:\n",
    "                \n",
    "                #Set search range be 400 ms\n",
    "                search_start = max(0, coarse_start - int(0.4 * sfreq))\n",
    "                search_end = min(entire_time_len, coarse_start + int(0.4 * sfreq))\n",
    "                \n",
    "                \n",
    "                alpha_grad = np.abs(np.diff(alpha_envelope[search_start: search_end]))\n",
    "                theta_grad = np.abs(np.diff(theta_envelope[search_start: search_end]))\n",
    "                \n",
    "                #find peak of alpha and theta gradient\n",
    "                precise_alpha_idx = np.argmax(alpha_grad) + search_start\n",
    "                precise_theta_idx = np.argmax(theta_grad) + search_start\n",
    "                \n",
    "                #Take the earlier one as the task switch start and later one as the end\n",
    "                final_task_switch_start = min(precise_alpha_idx, precise_theta_idx)\n",
    "                final_task_switch_end = max(precise_alpha_idx, precise_theta_idx)\n",
    "                \n",
    "                verified_segments.append((final_task_switch_start, final_task_switch_end))\n",
    "    return verified_segments\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f16cd3",
   "metadata": {},
   "source": [
    "## Step 3:Check by GFP\n",
    "\n",
    "3 Part in this function:  \n",
    "Part A: There exist lowest GFP in the range of (300ms before task switch start) to (100ms after task switch end) compare to other time. The reason behaind is before task switch brand will shut down most part of brain. The range base on alpha and theta not 100% accurate, so use more time to make sure. Therefore check the lowest GFP in the range of (1500ms before task switch start) to (300ms after task switch end) also in (300ms before task switch start) to (100ms after task switch end).  \n",
    "\n",
    "Part B: Check the mean of lowest GFP in the range of (300ms before task switch start) to (task switch end). The GFP decrease before task switch start and increase after task switch end.  So the mean of 1500ms before task switch start to 300ms should be less than then mean of (300ms before task switch start)'s GFP\n",
    "\n",
    "Part C: From paper, before the task switch, there will be a 20hz to 50hz GFP decrease trend,so try to find the 6 decrease(23ms in 256hz) trend exist in (300ms before task switch start) to (task switch end).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the GFP (Global Field Power) of an EEG signal.\n",
    "def calculate_GFP(eeg_data_frame, sfreq=256):\n",
    "    \"\"\"\n",
    "        Calculate the Global Field Power (GFP) of an EEG data.\n",
    "        Assume data structure is Pandas DataFrame with columns as channels and rows as time points.\n",
    "    \"\"\"\n",
    "    #GFP is the SD of every time point across all channels(column)\n",
    "    #Count and trans to numpy array\n",
    "    gfp = eeg_data_frame.std(axis=1).values\n",
    "    \n",
    "    #Use 30ms as the smoothing range\n",
    "    smooth_range = int(0.03 * sfreq)\n",
    "    # Simple moving about 43ms smoothing removes extremely high frequency spikes\n",
    "    #WHY: \n",
    "        #Assume noise can't 100% remove, so noise can make spikes happen.\n",
    "        #Make spikes more obvious by averaging them out.\n",
    "    smooth_gfp = np.convolve(gfp, np.ones(smooth_range)/smooth_range, mode='same')\n",
    "    \n",
    "    return smooth_gfp\n",
    "\n",
    "def gfp_check(candidate_task_switch, smooth_gfp, sfreq=256):\n",
    "    #Set variable\n",
    "    verified_segments = []\n",
    "    \n",
    "    #Set task switch range before and after. 300ms before start time and 100ms after end time.\n",
    "    before_check_range = int(0.3 * sfreq)\n",
    "    after_check_range = int(0.1 * sfreq)\n",
    "    \n",
    "    \n",
    "#Can change later after discussing \n",
    "    #The check lowest GFP range. 1500 ms before task switch until 300ms after task switch end.\n",
    "        #For alpha and theta, it may change in 200ms. But consider the task swich is happened in undreds to thousands of milliseconds,\n",
    "            #So we set the check range to 1500ms before and 300ms later.\n",
    "    check_lowest_range_before = int(1.5*sfreq)\n",
    "    check_lowest_range_after = int(0.3*sfreq)\n",
    "    \n",
    "    #Check average GFP in the check range is decrease(350hs)\n",
    "    pre_avg_smp = int(0.350 * sfreq)\n",
    "    \n",
    "    #use 25ms as the minumum decrease trend scope\n",
    "    decrease_scope = int(0.025 * sfreq)\n",
    "    \n",
    "    \n",
    "    for start, end in candidate_task_switch:\n",
    "        #Assume large task switch not happen in the first 1500ms\n",
    "        if start < check_lowest_range_before:\n",
    "            continue\n",
    "        \n",
    "        #Part A:\n",
    "        #Set the actuall range of evaluation lowest GFP\n",
    "        lowest_GFP_check_start = start - check_lowest_range_before\n",
    "        lowest_GFP_check_end = min(len(smooth_gfp),end + check_lowest_range_after)\n",
    "\n",
    "        #Check the lowest GFP in the range\n",
    "        gfp_check_data = smooth_gfp[lowest_GFP_check_start : lowest_GFP_check_end]\n",
    "        #Find the lowest GFP in the range\n",
    "        lowest_gfp = np.argmin(gfp_check_data) + lowest_GFP_check_start\n",
    "        \n",
    "        \n",
    "        start_check_point = start - before_check_range\n",
    "        end_check_point = min(len(smooth_gfp), end + after_check_range)\n",
    "        #Check the GFP lowest point of (1500ms+start) to (300ms+end) is also in (300ms+start) to (100ms+end)\n",
    "        is_lowest_in_task_switch = (start_check_point <= lowest_gfp <= end_check_point)\n",
    "        \n",
    "        #If the lowest GFP is not in the task switch range, continue to next candidate\n",
    "        if not is_lowest_in_task_switch:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #Part B:\n",
    "        #Then, check the average GFP near to start are less than far way to start.\n",
    "        #In this function, compare 1500ms to 350ms before start time and 350ms before start time\n",
    "        average_futher_GFP = np.mean(smooth_gfp[start - check_lowest_range_before : start - pre_avg_smp])\n",
    "        average_near_GFP = np.mean(smooth_gfp[start - pre_avg_smp : start])\n",
    "        \n",
    "        if average_near_GFP > average_futher_GFP:\n",
    "            continue\n",
    "    \n",
    "\n",
    "        #Part C:\n",
    "        #Check is there exits 25ms GFP decrease trend in 300hs before start to end time.\n",
    "        \n",
    "        #Consider the range is same with find lowest GFP, so just use the variable before\n",
    "        search_trend_data = smooth_gfp[start_check_point : end]\n",
    "        diffs = np.diff(search_trend_data)\n",
    "        \n",
    "        decrease_count = 0\n",
    "        find_decrease_trend = False\n",
    "        for each in diffs:\n",
    "            if each > 0:\n",
    "                decrease_count = 0\n",
    "            else:\n",
    "                decrease_count += 1\n",
    "            #In 256hz, the 6 points is about 23ms.\n",
    "            #If there are 20 hz is decrease, it means decrease trend exist.\n",
    "            if decrease_count >= 6:\n",
    "                find_decrease_trend = True\n",
    "                break\n",
    "        if find_decrease_trend:\n",
    "            verified_segments.append((start, end))\n",
    "    \n",
    "    return verified_segments\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de997ed",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
